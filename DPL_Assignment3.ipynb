{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"u3qkyJGBYidr"},"outputs":[],"source":["try:\n","  import google.colab\n","  IN_COLAB= True\n","except:\n","  IN_COLAB = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15249,"status":"ok","timestamp":1700445423021,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"},"user_tz":420},"id":"fG93VmqJZrgL","outputId":"0c02cbb9-d191-4111-b30b-8d3c638b170f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["if IN_COLAB:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive/')"]},{"cell_type":"code","source":["!pip install numba"],"metadata":{"id":"39v8Sfth2pKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jf2yzNRsmmDz"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from numba import cuda\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import SnowballStemmer\n","import re\n","\n","import sys\n","import warnings\n","\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JY9pJ-dU927f","executionInfo":{"status":"ok","timestamp":1700445458425,"user_tz":420,"elapsed":1712,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"}},"outputId":"7f1c0584-e9f8-426c-ee76-28e10600b2b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Load and Preprocess datasets"],"metadata":{"id":"_ugJ5XXgqS2v"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YxPrL8Nqvrd"},"outputs":[],"source":["train_set = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/DPL_Assignment3/train.csv')\n","\n","test_set = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/DPL_Assignment3/test.csv')\n","\n","validation_set = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/DPL_Assignment3/validation.csv')"]},{"cell_type":"markdown","metadata":{"id":"1wISmxK3ykYv"},"source":["Remove empty values and NaNs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvI50l4cwPFR"},"outputs":[],"source":["filter = train_set[\"Tweet\"] != \"\"\n","train_set = train_set[filter]\n","train_set = train_set.dropna()\n","\n","\n","filter = test_set[\"Tweet\"] != \"\"\n","test_set = test_set[filter]\n","test_set = test_set.dropna()\n","\n","\n","filter = validation_set[\"Tweet\"] != \"\"\n","validation_set = validation_set[filter]\n","validation_set = validation_set.dropna()"]},{"cell_type":"markdown","metadata":{"id":"eXjMIG8Ny2zZ"},"source":["Convert Boolean values to binary values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QyzbS8qxm0w"},"outputs":[],"source":["train_set = train_set.replace(True, 1)\n","train_set = train_set.replace(False, 0)\n","\n","test_set = test_set.replace(True, 1)\n","test_set = test_set.replace(False, 0)\n","\n","validation_set = validation_set.replace(True, 1)\n","validation_set = validation_set.replace(False, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ognEKKQz22Hc"},"outputs":[],"source":["# Convert to lowercase.\n","train_set['Tweet'] = train_set[\"Tweet\"].str.lower()\n","test_set['Tweet'] = test_set[\"Tweet\"].str.lower()\n","validation_set['Tweet'] = validation_set[\"Tweet\"].str.lower()\n","\n","# Remove special characters and punctuation\n","train_set['Tweet'] = train_set[\"Tweet\"].replace('[^\\sa-zA-Z]+', '', regex=True)\n","test_set['Tweet'] = test_set[\"Tweet\"].replace('[^\\sa-zA-Z]+', '', regex=True)\n","validation_set['Tweet'] = validation_set[\"Tweet\"].replace('[^\\sa-zA-Z]+', '', regex=True)"]},{"cell_type":"code","source":["stop_words = set(stopwords.words('english'))\n","\n","re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n","\n","def remove_stopwords(sentence):\n","  global re_stop_words\n","  return re_stop_words.sub(\" \", sentence)\n","\n","\n","train_set[\"Tweet\"] = train_set[\"Tweet\"].apply(remove_stopwords)\n","test_set[\"Tweet\"] = test_set[\"Tweet\"].apply(remove_stopwords)\n","validation_set[\"Tweet\"] = validation_set[\"Tweet\"].apply(remove_stopwords)"],"metadata":{"id":"D1k5wFPS9imx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stemmer = SnowballStemmer('english')\n","\n","def stemming(sentence):\n","  stemSentence = \"\"\n","  for word in sentence.split():\n","    stem = stemmer.stem(word)\n","    stemSentence += stem + \" \"\n","  stemSentence = stemSentence.strip()\n","  return stemSentence\n","\n","train_set[\"Tweet\"] = train_set[\"Tweet\"].apply(stemming)\n","test_set[\"Tweet\"] = test_set[\"Tweet\"].apply(stemming)\n","validation_set[\"Tweet\"] = validation_set[\"Tweet\"].apply(stemming)"],"metadata":{"id":"JzMWGkgmAqGO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Making Dataset"],"metadata":{"id":"bbfKUV1Fj5dT"}},{"cell_type":"code","source":["def make_labels_list(dataframe):\n","  labels = []\n","  labels_list = pd.DataFrame(columns=['Tweet','Terms'])\n","\n","  for i in range(len(dataframe)):\n","    for j in range(2, 13):\n","      if j == 1 and dataframe.iat[i,j] == 1:\n","        labels.append('anger')\n","      if j == 2 and dataframe.iat[i,j] == 1:\n","        labels.append('anticipation')\n","      if j == 3 and dataframe.iat[i,j] == 1:\n","        labels.append('disgust')\n","      if j == 4 and dataframe.iat[i,j] == 1:\n","        labels.append('fear')\n","      if j == 5 and dataframe.iat[i,j] == 1:\n","        labels.append('joy')\n","      if j == 6 and dataframe.iat[i,j] == 1:\n","        labels.append('love')\n","      if j == 7 and dataframe.iat[i,j] == 1:\n","        labels.append('optimism')\n","      if j == 8 and dataframe.iat[i,j] == 1:\n","        labels.append('pessimism')\n","      if j == 9 and dataframe.iat[i,j] == 1:\n","        labels.append('sadness')\n","      if j == 10 and dataframe.iat[i,j] == 1:\n","        labels.append('surprise')\n","      if j == 11 and dataframe.iat[i,j] == 1:\n","        labels.append('trust')\n","\n","    labels_list.at[i, 'Tweet'] = dataframe.at[i, 'Tweet']\n","    labels_list.at[i, 'Terms'] = labels\n","    labels = []\n","\n","  return labels_list"],"metadata":{"id":"rKMKSpTPWGcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = make_labels_list(train_set)\n","test_dataset = make_labels_list(test_set)\n","validation_dataset = make_labels_list(validation_set)"],"metadata":{"id":"cpgTxU1LkDez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["terms = tf.ragged.constant(train_dataset[\"Terms\"].values)\n","lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n","lookup.adapt(terms)\n","vocab = lookup.get_vocabulary()\n","\n","\n","def invert_multi_hot(encoded_labels):\n","    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n","    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n","    return np.take(vocab, hot_indices)\n","\n","\n","print(\"Vocabulary:\\n\")\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHGtaqc7wu-E","executionInfo":{"status":"ok","timestamp":1700445493945,"user_tz":420,"elapsed":4164,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"}},"outputId":"350e6d26-1c2e-4931-fdeb-8f56fb7cef60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary:\n","\n","['[UNK]', 'fear', 'anticipation', 'love', 'surprise', 'pessimism', 'joy', 'disgust', 'sadness', 'optimism', 'trust']\n"]}]},{"cell_type":"code","source":["max_seqlen = 15\n","batch_size = 64\n","padding_token = \"<pad>\"\n","auto = tf.data.AUTOTUNE\n","\n","def make_dataset(dataframe, is_train=True):\n","\n","    labels = tf.ragged.constant(dataframe[\"Terms\"].values)\n","    label_binarized = lookup(labels).numpy()\n","    dataset = tf.data.Dataset.from_tensor_slices(\n","        (dataframe[\"Tweet\"].values, label_binarized)\n","    )\n","    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n","    return dataset.batch(batch_size)"],"metadata":{"id":"4botJ74fP8Ro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = tf.ragged.constant(test_dataset[\"Terms\"].values)\n","binarized_test_labels = lookup(labels)"],"metadata":{"id":"kh0AueW983Pr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = make_dataset(train_dataset, is_train=True)\n","validation_dataset = make_dataset(validation_dataset, is_train=False)"],"metadata":{"id":"0QmFllJFQA-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocabulary = set()\n","train_set[\"Tweet\"].str.lower().str.split().apply(vocabulary.update)\n","vocabulary_size = len(vocabulary)\n","print(vocabulary_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiA4C9u01rrV","executionInfo":{"status":"ok","timestamp":1700445496371,"user_tz":420,"elapsed":4,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"}},"outputId":"520166ef-f414-463e-e138-03ada1585f96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["13312\n"]}]},{"cell_type":"code","source":["text_vectorizer = layers.TextVectorization(\n","    max_tokens=vocabulary_size,\n","    ngrams=2,\n","    output_mode=\"tf_idf\"\n",")\n","\n","text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n","\n","train_dataset = train_dataset.map(\n","    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n","\n","validation_dataset = validation_dataset.map(\n","    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n","\n","test_dataset = text_vectorizer(test_dataset[\"Tweet\"])"],"metadata":{"id":"qGTCARIf2Afi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J9TJypyzChJm"},"source":["## Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_sjDYwBclbN"},"outputs":[],"source":["model = Sequential([\n","    tf.keras.layers.Reshape((2, -1), input_shape=(13312,)),\n","    layers.Bidirectional(layers.LSTM(3328, input_shape=(6656, 2), return_sequences=True)),\n","    layers.Flatten(),\n","    layers.Dense(1664, activation=\"relu\"),\n","    layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\")\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Iv7XrIvdqQ8"},"outputs":[],"source":["model.compile(\n","  optimizer=tf.keras.optimizers.Adam(1e-4),\n","  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n","  metrics=[tf.keras.metrics.Recall()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0O642KJp4In","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700445592577,"user_tz":420,"elapsed":111,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"}},"outputId":"27acff71-d61d-43ec-a34c-565012b1c81f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," reshape (Reshape)           (None, 2, 6656)           0         \n","                                                                 \n"," bidirectional (Bidirection  (None, 2, 6656)           265840640 \n"," al)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 13312)             0         \n","                                                                 \n"," dense (Dense)               (None, 1664)              22152832  \n","                                                                 \n"," dense_1 (Dense)             (None, 11)                18315     \n","                                                                 \n","=================================================================\n","Total params: 288011787 (1.07 GB)\n","Trainable params: 288011787 (1.07 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"uitPOdQHmJmD"},"source":["## Fit and predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-NWPdmweDCr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700446090882,"user_tz":420,"elapsed":490942,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"}},"outputId":"77c7e2e9-feed-4716-92b6-069c5f77f90a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/53\n","107/107 [==============================] - 19s 73ms/step - loss: 0.4448 - recall: 0.1570 - val_loss: 0.3941 - val_recall: 0.3211\n","Epoch 2/53\n","107/107 [==============================] - 7s 66ms/step - loss: 0.2983 - recall: 0.5420 - val_loss: 0.3609 - val_recall: 0.4788\n","Epoch 3/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.2156 - recall: 0.6873 - val_loss: 0.3862 - val_recall: 0.5212\n","Epoch 4/53\n","107/107 [==============================] - 7s 65ms/step - loss: 0.1623 - recall: 0.7785 - val_loss: 0.4478 - val_recall: 0.5373\n","Epoch 5/53\n","107/107 [==============================] - 7s 68ms/step - loss: 0.1267 - recall: 0.8386 - val_loss: 0.5330 - val_recall: 0.5425\n","Epoch 6/53\n","107/107 [==============================] - 7s 67ms/step - loss: 0.1011 - recall: 0.8799 - val_loss: 0.6145 - val_recall: 0.5477\n","Epoch 7/53\n","107/107 [==============================] - 7s 70ms/step - loss: 0.0862 - recall: 0.9002 - val_loss: 0.6760 - val_recall: 0.5703\n","Epoch 8/53\n","107/107 [==============================] - 7s 65ms/step - loss: 0.0728 - recall: 0.9194 - val_loss: 0.7712 - val_recall: 0.5420\n","Epoch 9/53\n","107/107 [==============================] - 7s 65ms/step - loss: 0.0641 - recall: 0.9282 - val_loss: 0.8528 - val_recall: 0.5335\n","Epoch 10/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0567 - recall: 0.9382 - val_loss: 0.9280 - val_recall: 0.5477\n","Epoch 11/53\n","107/107 [==============================] - 7s 66ms/step - loss: 0.0498 - recall: 0.9453 - val_loss: 0.9590 - val_recall: 0.5576\n","Epoch 12/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0460 - recall: 0.9497 - val_loss: 1.0426 - val_recall: 0.5113\n","Epoch 13/53\n","107/107 [==============================] - 7s 66ms/step - loss: 0.0415 - recall: 0.9540 - val_loss: 1.0677 - val_recall: 0.5562\n","Epoch 14/53\n","107/107 [==============================] - 7s 67ms/step - loss: 0.0375 - recall: 0.9605 - val_loss: 1.1202 - val_recall: 0.5534\n","Epoch 15/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0336 - recall: 0.9637 - val_loss: 1.2166 - val_recall: 0.5340\n","Epoch 16/53\n","107/107 [==============================] - 7s 69ms/step - loss: 0.0315 - recall: 0.9659 - val_loss: 1.2603 - val_recall: 0.5194\n","Epoch 17/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0295 - recall: 0.9679 - val_loss: 1.2720 - val_recall: 0.5288\n","Epoch 18/53\n","107/107 [==============================] - 7s 68ms/step - loss: 0.0261 - recall: 0.9733 - val_loss: 1.2947 - val_recall: 0.5590\n","Epoch 19/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0233 - recall: 0.9766 - val_loss: 1.3868 - val_recall: 0.5444\n","Epoch 20/53\n","107/107 [==============================] - 7s 65ms/step - loss: 0.0229 - recall: 0.9752 - val_loss: 1.4243 - val_recall: 0.5241\n","Epoch 21/53\n","107/107 [==============================] - 7s 69ms/step - loss: 0.0227 - recall: 0.9770 - val_loss: 1.4187 - val_recall: 0.5727\n","Epoch 22/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0204 - recall: 0.9789 - val_loss: 1.4398 - val_recall: 0.5604\n","Epoch 23/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0206 - recall: 0.9797 - val_loss: 1.4471 - val_recall: 0.5751\n","Epoch 24/53\n","107/107 [==============================] - 7s 66ms/step - loss: 0.0182 - recall: 0.9829 - val_loss: 1.5037 - val_recall: 0.5713\n","Epoch 25/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0155 - recall: 0.9839 - val_loss: 1.5535 - val_recall: 0.5581\n","Epoch 26/53\n","107/107 [==============================] - 7s 69ms/step - loss: 0.0147 - recall: 0.9855 - val_loss: 1.6281 - val_recall: 0.5354\n","Epoch 27/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0131 - recall: 0.9866 - val_loss: 1.6333 - val_recall: 0.5571\n","Epoch 28/53\n","107/107 [==============================] - 7s 67ms/step - loss: 0.0119 - recall: 0.9888 - val_loss: 1.6536 - val_recall: 0.5543\n","Epoch 29/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0115 - recall: 0.9896 - val_loss: 1.7134 - val_recall: 0.5477\n","Epoch 30/53\n","107/107 [==============================] - 7s 65ms/step - loss: 0.0108 - recall: 0.9900 - val_loss: 1.7152 - val_recall: 0.5467\n","Epoch 31/53\n","107/107 [==============================] - 7s 69ms/step - loss: 0.0100 - recall: 0.9909 - val_loss: 1.7876 - val_recall: 0.5378\n","Epoch 32/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0085 - recall: 0.9920 - val_loss: 1.8181 - val_recall: 0.5524\n","Epoch 33/53\n","107/107 [==============================] - 7s 69ms/step - loss: 0.0079 - recall: 0.9926 - val_loss: 1.8535 - val_recall: 0.5458\n","Epoch 34/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0080 - recall: 0.9930 - val_loss: 1.9028 - val_recall: 0.5354\n","Epoch 35/53\n","107/107 [==============================] - 7s 67ms/step - loss: 0.0078 - recall: 0.9933 - val_loss: 1.9307 - val_recall: 0.5354\n","Epoch 36/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0068 - recall: 0.9934 - val_loss: 1.9935 - val_recall: 0.5420\n","Epoch 37/53\n","107/107 [==============================] - 7s 69ms/step - loss: 0.0090 - recall: 0.9911 - val_loss: 1.9618 - val_recall: 0.5472\n","Epoch 38/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0120 - recall: 0.9901 - val_loss: 1.8544 - val_recall: 0.5543\n","Epoch 39/53\n","107/107 [==============================] - 7s 69ms/step - loss: 0.0103 - recall: 0.9918 - val_loss: 1.9128 - val_recall: 0.5250\n","Epoch 40/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0093 - recall: 0.9932 - val_loss: 1.9056 - val_recall: 0.5623\n","Epoch 41/53\n","107/107 [==============================] - 7s 70ms/step - loss: 0.0081 - recall: 0.9931 - val_loss: 1.9488 - val_recall: 0.5368\n","Epoch 42/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0072 - recall: 0.9939 - val_loss: 1.9924 - val_recall: 0.5312\n","Epoch 43/53\n","107/107 [==============================] - 7s 67ms/step - loss: 0.0075 - recall: 0.9934 - val_loss: 1.9712 - val_recall: 0.5567\n","Epoch 44/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0075 - recall: 0.9940 - val_loss: 1.9394 - val_recall: 0.5548\n","Epoch 45/53\n","107/107 [==============================] - 7s 65ms/step - loss: 0.0074 - recall: 0.9945 - val_loss: 1.9687 - val_recall: 0.5406\n","Epoch 46/53\n","107/107 [==============================] - 7s 68ms/step - loss: 0.0064 - recall: 0.9946 - val_loss: 1.9567 - val_recall: 0.5623\n","Epoch 47/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0064 - recall: 0.9939 - val_loss: 1.9973 - val_recall: 0.5364\n","Epoch 48/53\n","107/107 [==============================] - 7s 67ms/step - loss: 0.0062 - recall: 0.9947 - val_loss: 1.9775 - val_recall: 0.5486\n","Epoch 49/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0080 - recall: 0.9948 - val_loss: 1.9618 - val_recall: 0.5335\n","Epoch 50/53\n","107/107 [==============================] - 7s 65ms/step - loss: 0.0075 - recall: 0.9944 - val_loss: 2.0307 - val_recall: 0.5425\n","Epoch 51/53\n","107/107 [==============================] - 7s 69ms/step - loss: 0.0071 - recall: 0.9953 - val_loss: 2.0020 - val_recall: 0.5430\n","Epoch 52/53\n","107/107 [==============================] - 7s 64ms/step - loss: 0.0068 - recall: 0.9949 - val_loss: 2.0153 - val_recall: 0.5434\n","Epoch 53/53\n","107/107 [==============================] - 7s 66ms/step - loss: 0.0077 - recall: 0.9946 - val_loss: 1.9832 - val_recall: 0.5557\n"]}],"source":["history = model.fit(\n","    train_dataset,\n","    epochs=53,\n","    validation_data=(validation_dataset)\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n76bccQYrQTq","outputId":"d53f15a7-1c4a-482a-90a7-0b0cd82c23d0","executionInfo":{"status":"ok","timestamp":1700446093645,"user_tz":420,"elapsed":2786,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["102/102 [==============================] - 2s 19ms/step - loss: 1.8445 - recall: 0.5660\n","Test Loss: 1.8444955348968506\n","Test Accuracy: 0.5659668445587158\n"]}],"source":["test_loss, test_acc = model.evaluate(test_dataset, binarized_test_labels)\n","\n","print('Test Loss:', test_loss)\n","print('Test Accuracy:', test_acc)"]},{"cell_type":"code","source":["predicted_probabilities = model.predict(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9p5PNZFq9tea","executionInfo":{"status":"ok","timestamp":1700446097283,"user_tz":420,"elapsed":3643,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"}},"outputId":"c3f51712-692d-41c9-daf8-32ce13918528"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["102/102 [==============================] - 3s 16ms/step\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPoOBtMdsbVE","outputId":"d6311431-dd1b-4021-adc4-aa36216f783f","executionInfo":{"status":"ok","timestamp":1700446097284,"user_tz":420,"elapsed":21,"user":{"displayName":"Wesley Johnson","userId":"08366907941510748266"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       anger       0.00      0.00      0.00         0\n","anticipation       0.60      0.55      0.58      1099\n","     disgust       0.70      0.60      0.65      1101\n","        fear       0.73      0.78      0.75      1442\n","         joy       0.55      0.55      0.55       960\n","        love       0.58      0.56      0.57      1143\n","    optimism       0.55      0.66      0.60       485\n","   pessimism       0.21      0.22      0.21       425\n","     sadness       0.29      0.24      0.26       375\n","    surprise       0.52      0.50      0.51       516\n","       trust       0.19      0.22      0.21       170\n","\n","   micro avg       0.57      0.57      0.57      7716\n","   macro avg       0.45      0.44      0.44      7716\n","weighted avg       0.57      0.57      0.57      7716\n"," samples avg       0.58      0.58      0.55      7716\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["labels = ['anger','anticipation','disgust','fear','joy','love','optimism','pessimism','sadness','surprise','trust']\n","\n","print(classification_report(binarized_test_labels.numpy(), predicted_probabilities.round(), target_names=labels))"]},{"cell_type":"markdown","source":["## Reset Device RAM"],"metadata":{"id":"anhOObGF3r1-"}},{"cell_type":"code","source":["device = cuda.get_current_device()\n","device.reset()"],"metadata":{"id":"EXiTv9cQ2uqX"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["anhOObGF3r1-"],"authorship_tag":"ABX9TyNv9YP/WUqd3LiPjL+TbBuY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}